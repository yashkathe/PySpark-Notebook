# Apache Spark with PySpark

Suppose our training data keeps on increasing  
or  
SQL query keeps on running all day  

What can we do ?  
-> Buy bigger machine  

OR just use `APACHE SPARK`  
-> Takes the Big Data problem and gives much quicker and affordable solutions  