{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoNHxZHM_zPp",
        "outputId": "602bee71-1bc0-4402-fba9-e8ad551d14ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=f514ccddbba9eda486934110cb922d51aa3d1b8970f7ede7c0bcfe0da786df19\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "mvBJhgS5AbE_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, filename):\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        print(f\"File downloaded successfully and saved as {filename}\")\n",
        "    except requests.exceptions.HTTPError as errh:\n",
        "        print(f\"HTTP Error: {errh}\")\n",
        "    except requests.exceptions.ConnectionError as errc:\n",
        "        print(f\"Error Connecting: {errc}\")\n",
        "    except requests.exceptions.Timeout as errt:\n",
        "        print(f\"Timeout Error: {errt}\")\n",
        "    except requests.exceptions.RequestException as err:\n",
        "        print(f\"OOps: Something Else: {err}\")"
      ],
      "metadata": {
        "id": "Q-YNJBjzAcni"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/prasertcbs/basic-dataset/master/Employee%20data.csv'\n",
        "filename = 'data.csv'\n",
        "\n",
        "download_file(url, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtAucBaVAfGa",
        "outputId": "035bb36a-168d-47e7-e147-fab4cdef2338"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully and saved as data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "nDS0bWo3AgyU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('DataFrame').getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "sWB5QVepAhbX",
        "outputId": "953176fd-e4f5-467c-a2e8-3a153316e295"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7ea8751bee00>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://3c6bc7f69653:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>DataFrame</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.csv('data.csv', header=True, inferSchema=True)\n",
        "df_pyspark.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqhqso2VAkm8",
        "outputId": "9fdfabd6-b09b-4bf4-fd47-5618f7efad0f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----------+----+--------+-------+--------+-------+-------+--------+\n",
            "| id|gender|     bdate|educ|  jobcat| salary|salbegin|jobtime|prevexp|minority|\n",
            "+---+------+----------+----+--------+-------+--------+-------+-------+--------+\n",
            "|1.0|  Male|1952-02-03|  15| Manager|57000.0| 27000.0|   98.0|  144.0|      No|\n",
            "|2.0|  Male|1958-05-23|  16|Clerical|40200.0| 18750.0|   98.0|   36.0|      No|\n",
            "|3.0|Female|1929-07-26|  12|Clerical|21450.0| 12000.0|   98.0|  381.0|      No|\n",
            "|4.0|Female|1947-04-15|   8|Clerical|21900.0| 13200.0|   98.0|  190.0|      No|\n",
            "|5.0|  Male|1955-02-09|  15|Clerical|45000.0| 21000.0|   98.0|  138.0|      No|\n",
            "+---+------+----------+----+--------+-------+--------+-------+-------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWj8ZvVYBhLi",
        "outputId": "f56a537d-e959-473c-87ec-ab4d2d444ec5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: double (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- bdate: date (nullable = true)\n",
            " |-- educ: integer (nullable = true)\n",
            " |-- jobcat: string (nullable = true)\n",
            " |-- salary: double (nullable = true)\n",
            " |-- salbegin: double (nullable = true)\n",
            " |-- jobtime: double (nullable = true)\n",
            " |-- prevexp: string (nullable = true)\n",
            " |-- minority: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "remove null rows"
      ],
      "metadata": {
        "id": "eQ1YGa0ECBxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark=df_pyspark.na.drop()\n",
        "df_pyspark.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-APW9O3BmFQ",
        "outputId": "007e4a47-bb04-4d5a-807d-7941b80d0a43"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----------+----+--------+-------+--------+-------+-------+--------+\n",
            "| id|gender|     bdate|educ|  jobcat| salary|salbegin|jobtime|prevexp|minority|\n",
            "+---+------+----------+----+--------+-------+--------+-------+-------+--------+\n",
            "|1.0|  Male|1952-02-03|  15| Manager|57000.0| 27000.0|   98.0|  144.0|      No|\n",
            "|2.0|  Male|1958-05-23|  16|Clerical|40200.0| 18750.0|   98.0|   36.0|      No|\n",
            "|3.0|Female|1929-07-26|  12|Clerical|21450.0| 12000.0|   98.0|  381.0|      No|\n",
            "|4.0|Female|1947-04-15|   8|Clerical|21900.0| 13200.0|   98.0|  190.0|      No|\n",
            "|5.0|  Male|1955-02-09|  15|Clerical|45000.0| 21000.0|   98.0|  138.0|      No|\n",
            "+---+------+----------+----+--------+-------+--------+-------+-------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vector Assembler\n",
        "\n",
        "To group features together"
      ],
      "metadata": {
        "id": "skIUbIiGCYKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "metadata": {
        "id": "j3Lwtt8NCdMb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "takes two argument\n",
        "1. inputCols\n",
        "2. outputCol"
      ],
      "metadata": {
        "id": "pXsEehKNCxXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new Column\n",
        "\n",
        "feature_assembler = VectorAssembler(inputCols=[\"educ\", \"salbegin\", \"jobtime\"], outputCol=\"Independent_Features\")"
      ],
      "metadata": {
        "id": "Xh0fzDEkClGZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = feature_assembler.transform(df_pyspark)"
      ],
      "metadata": {
        "id": "TvikL0BGDYlm"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43beBIjqDjZP",
        "outputId": "da54bba3-ce73-4a75-91c5-316c0922c493"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----------+----+--------+-------+--------+-------+-------+--------+-----------+--------------------+\n",
            "| id|gender|     bdate|educ|  jobcat| salary|salbegin|jobtime|prevexp|minority|prevexp-int|Independent_Features|\n",
            "+---+------+----------+----+--------+-------+--------+-------+-------+--------+-----------+--------------------+\n",
            "|1.0|  Male|1952-02-03|  15| Manager|57000.0| 27000.0|   98.0|  144.0|      No|        144| [15.0,27000.0,98.0]|\n",
            "|2.0|  Male|1958-05-23|  16|Clerical|40200.0| 18750.0|   98.0|   36.0|      No|         36| [16.0,18750.0,98.0]|\n",
            "|3.0|Female|1929-07-26|  12|Clerical|21450.0| 12000.0|   98.0|  381.0|      No|        381| [12.0,12000.0,98.0]|\n",
            "|4.0|Female|1947-04-15|   8|Clerical|21900.0| 13200.0|   98.0|  190.0|      No|        190|  [8.0,13200.0,98.0]|\n",
            "|5.0|  Male|1955-02-09|  15|Clerical|45000.0| 21000.0|   98.0|  138.0|      No|        138| [15.0,21000.0,98.0]|\n",
            "+---+------+----------+----+--------+-------+--------+-------+-------+--------+-----------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "take only necessary columns now\n",
        "\n",
        "-> based on `Independent_Features` predict `salary`"
      ],
      "metadata": {
        "id": "KTOXbvf3FzFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finalized_data = output.select(\"Independent_Features\", \"salary\")\n",
        "finalized_data.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msEI4wreF0xl",
        "outputId": "efe462dc-e251-4f5f-8927-f430a8bdf3d3"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------+\n",
            "|Independent_Features| salary|\n",
            "+--------------------+-------+\n",
            "| [15.0,27000.0,98.0]|57000.0|\n",
            "| [16.0,18750.0,98.0]|40200.0|\n",
            "| [12.0,12000.0,98.0]|21450.0|\n",
            "|  [8.0,13200.0,98.0]|21900.0|\n",
            "| [15.0,21000.0,98.0]|45000.0|\n",
            "+--------------------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test split"
      ],
      "metadata": {
        "id": "dYrQexGFGMW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import LinearRegression"
      ],
      "metadata": {
        "id": "WdojAMGKGONf"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,test_data=finalized_data.randomSplit([0.75,0.25])"
      ],
      "metadata": {
        "id": "9GVJBOcmGYmP"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor=LinearRegression(featuresCol='Independent_Features', labelCol='salary')\n",
        "regressor=regressor.fit(train_data)"
      ],
      "metadata": {
        "id": "DD8Ga0kxGgVg"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "coefficients and intercepts"
      ],
      "metadata": {
        "id": "vkm4b1m2Gqqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.coefficients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyOUpg44GuMw",
        "outputId": "bf549881-72c4-4654-c233-44f4ee202df2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseVector([924.4474, 1.7515, 156.3267])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regressor.intercept"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si_Nm7f_GgOR",
        "outputId": "205a63c4-c03c-429b-bde2-94b04d3f3fc3"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-20478.107892954664"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results=regressor.evaluate(test_data)"
      ],
      "metadata": {
        "id": "uN9-Y1PuGxgr"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results.predictions.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0QVm5P6G1Tq",
        "outputId": "5f37796a-d0b6-430c-a467-21b73fab1e97"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------+------------------+\n",
            "|Independent_Features| salary|        prediction|\n",
            "+--------------------+-------+------------------+\n",
            "|  [8.0,10950.0,81.0]|22500.0|18758.657454794833|\n",
            "|  [8.0,10950.0,92.0]|24000.0|20478.251484842105|\n",
            "|  [8.0,11250.0,96.0]|31350.0|21629.002823072733|\n",
            "|  [8.0,12450.0,74.0]|21750.0|20291.592435831975|\n",
            "|  [8.0,13200.0,88.0]|20100.0| 23793.77770142575|\n",
            "|  [8.0,13500.0,65.0]|21600.0| 20723.70732954036|\n",
            "|  [8.0,14250.0,95.0]|29250.0|26727.120275202884|\n",
            "|  [8.0,15000.0,87.0]|30750.0|26790.117480702116|\n",
            "|  [8.0,15750.0,67.0]|30000.0|24977.193926149783|\n",
            "|  [8.0,15750.0,74.0]|31950.0|26071.481036179866|\n",
            "|  [8.0,15750.0,78.0]|24000.0|26696.787956197055|\n",
            "|  [12.0,9000.0,91.0]|30750.0|20604.325512755764|\n",
            "| [12.0,10200.0,66.0]|16350.0| 18797.93493550211|\n",
            "| [12.0,10200.0,72.0]|19950.0|19735.895315527894|\n",
            "| [12.0,10200.0,84.0]|16500.0| 21611.81607557946|\n",
            "| [12.0,10500.0,92.0]|28500.0|23387.874333827283|\n",
            "| [12.0,10950.0,81.0]|19650.0| 22456.44693110018|\n",
            "| [12.0,10950.0,83.0]|20400.0|22769.100391108776|\n",
            "| [12.0,11225.0,81.0]|27750.0|22938.104314462507|\n",
            "| [12.0,11250.0,68.0]|22800.0| 20949.64385925776|\n",
            "+--------------------+-------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}